data <- data.frame(x = x, y = y)
data
sd(y)
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1, mean = 0, sd = 0.2)
x1 <- c(0, 0, 0)
x2 <- c(0, 0, 0)
y <- c(0, 0)
for(i in 3:(n_1+2){
y <- c(y, f1(x1[i])*x1[i]+ f2(x2[i])*x2[i] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1, mean = 0, sd = 0.2)
x1 <- c(0, 0, 0)
x2 <- c(0, 0, 0)
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(x1[i])*x1[i]+ f2(x2[i])*x2[i] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
x
x1
y
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
y
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
y1
y
x1
x2
x1[-c(1)]
x2[-c(1,2)]
y
y[-c(1,2,3,4)]
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
x1 <- x1[-c(1,2)]
x2 <- x2[-c(1,2)]
y <- y[-c(1,2,3,4)]
data <- data.frame(x1 = x1, x2 = x2, y = y)
data
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
y
x2[-c(1,2)]
x1[-c(1,2)]
y
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
x1 <- x1[-c(1,2)]
x2 <- x2[-c(1,2)]
y <- y[-c(1,2,3,4)]
data <- data.frame(x1 = x1, x2 = x2, y = y)
data
## Classification forest with default settings
rf <- ranger(y~., data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
x2 =seq(0, 1, length.out =n_test),
y = rep(0, n_test) ))
pred_1
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
pred_1$predictions
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
## Classification forest with default settings
rf <- ranger(y~x1+x2, data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
x2 =seq(0, 1, length.out =n_test),
y = rep(0, n_test) ))
pred_1$predictions
rm(list = ls(all.names = TRUE))
library(ranger)
library(rmutil)
#### case 1
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
x1 <- x1[-c(1,2)]
x2 <- x2[-c(1,2)]
y <- y[-c(1,2,3,4)]
data_old <- data.frame(x1 = x1, x2 = x2, y = y)
data_old
data <- data.frame(x1 = x1, x2 = x2, y1 = y, y2 = y)
data$y1 <- y/x1
data$y2 <- y/x2
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
pred_1$predictions
y1
data
y/x1
predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
rf1 <- ranger(y1~x1, data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
abline(h= 0)
?lm
i = 1
y_tmp <- y[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x1_tmp <- x1[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x2_tmp <- x2[((i-1)*bandwidth+1): ((i)*bandwidth) ]
coef <- lm(y_tmp~x1_tmp+x2_tmp)
bandwidth <- 10
data <- data.frame(x1 = x1, x2 = x2, y1 = y, y2 = y)
y_tmp <- y[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x1_tmp <- x1[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x2_tmp <- x2[((i-1)*bandwidth+1): ((i)*bandwidth) ]
coef <- lm(y_tmp~x1_tmp+x2_tmp)
lm(y_tmp~x1_tmp+x2_tmp)
lm(y_tmp~-1+x1_tmp+x2_tmp)
lm(y_tmp~-1+x1_tmp+x2_tmp)$Coefficients
tt <- lm(y_tmp~-1+x1_tmp+x2_tmp)
tt$coefficients
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[1]
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)]
coef <- lm(y_tmp~-1+x1_tmp+x2_tmp)$coefficients
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[1]
data$x1
data$y1
coef[1]
coef[[1]]
coef[[1]]
bandwidth <- 10
data <- data.frame(x1 = x1, x2 = x2, y1 = y, y2 = y)
y_tmp <- y[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x1_tmp <- x1[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x2_tmp <- x2[((i-1)*bandwidth+1): ((i)*bandwidth) ]
coef <- lm(y_tmp~-1+x1_tmp+x2_tmp)$coefficients
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[1]]
data$y1
data
rm(list = ls(all.names = TRUE))
library(ranger)
library(rmutil)
#### case 1
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
x1 <- x1[-c(1,2)]
x2 <- x2[-c(1,2)]
y <- y[-c(1,2,3,4)]
data_old <- data.frame(x1 = x1, x2 = x2, y = y)
data_old
bandwidth <- 10
data <- data.frame(x1 = x1, x2 = x2, y1 = y, y2 = y)
for(i in 1:(n_1/bandwidth)){
y_tmp <- y[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x1_tmp <- x1[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x2_tmp <- x2[((i-1)*bandwidth+1): ((i)*bandwidth) ]
coef <- lm(y_tmp~-1+x1_tmp+x2_tmp)$coefficients
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[1]]
data$y2[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[2]]
}
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
rm(list = ls(all.names = TRUE))
library(ranger)
library(rmutil)
#### case 1
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
x1 <- x1[-c(1,2)]
x2 <- x2[-c(1,2)]
y <- y[-c(1,2,3,4)]
data_old <- data.frame(x1 = x1, x2 = x2, y = y)
data_old
bandwidth <- 5
data <- data.frame(x1 = x1, x2 = x2, y1 = y, y2 = y)
for(i in 1:(n_1/bandwidth)){
y_tmp <- y[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x1_tmp <- x1[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x2_tmp <- x2[((i-1)*bandwidth+1): ((i)*bandwidth) ]
coef <- lm(y_tmp~-1+x1_tmp+x2_tmp)$coefficients
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[1]]
data$y2[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[2]]
}
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
pred_1$predictions
data
rm(list = ls(all.names = TRUE))
library(ranger)
library(rmutil)
#### case 1
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
f2 <- function(x){-0.437 - (0.659+ 1.260*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
x2 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1]+ f2(y[i-2])*y[i-2] + e[i])
x1 <- c(x1, y[i-1])
x2 <- c(x2, y[i-2])
}
x1 <- x1[-c(1,2)]
x2 <- x2[-c(1,2)]
y <- y[-c(1,2,3,4)]
data_old <- data.frame(x1 = x1, x2 = x2, y = y)
data_old
bandwidth <- 2
data <- data.frame(x1 = x1, x2 = x2, y1 = y, y2 = y)
for(i in 1:(n_1/bandwidth)){
y_tmp <- y[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x1_tmp <- x1[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x2_tmp <- x2[((i-1)*bandwidth+1): ((i)*bandwidth) ]
coef <- lm(y_tmp~-1+x1_tmp+x2_tmp)$coefficients
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[1]]
data$y2[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[2]]
}
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
data
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
rm(list = ls(all.names = TRUE))
library(ranger)
library(rmutil)
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1] + e[i])
x1 <- c(x1, y[i-1])
}
x1 <- x1[-c(1,2)]
y <- y[-c(1,2,3,4)]
data_old <- data.frame(x1 = x1, y = y)
data_old
bandwidth <- 2
data <- data.frame(x1 = x1, y1 = y)
for(i in 1:(n_1/bandwidth)){
y_tmp <- y[((i-1)*bandwidth+1): ((i)*bandwidth) ]
x1_tmp <- x1[((i-1)*bandwidth+1): ((i)*bandwidth) ]
coef <- lm(y_tmp~-1+x1_tmp)$coefficients
data$y1[((i-1)*bandwidth+1): ((i)*bandwidth)] <- coef[[1]]
}
bandwidth <- 1
data <- data.frame(x1 = x1, y1 = y)
data$y1 <- y/x1
rf1 <- ranger(y1~x1, data = data,
num.trees = 500,
min.node.size = floor(0.04*(log (n_1) )^4* log(log(n_1))),
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
floor(0.04*(log (n_1) )^4* log(log(n_1)))
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 100,
min.node.size = 10,
replace = FALSE, sample.fraction = 1
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 100,
min.node.size = 40,
replace = FALSE, sample.fraction = 1
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 100,
min.node.size = 40,
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 1000,
min.node.size = 40,
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 1000,
min.node.size = 20,
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 1000,
min.node.size = 30,
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
rm(list = ls(all.names = TRUE))
library(ranger)
library(rmutil)
f1 <- function(x){0.138 + (0.316+ 0.982*x)*exp(-3.89*x^2) }
n_test = 400
n_1 <- 400
e <- rnorm(n_1+2, mean = 0, sd = 0.2)
x1 <- c()
y <- c(0, 0)
for(i in c(3:(n_1+2) )){
y <- c(y, f1(y[i-1])*y[i-1] + e[i])
x1 <- c(x1, y[i-1])
}
x1 <- x1[-c(1,2)]
y <- y[-c(1,2,3,4)]
data_old <- data.frame(x1 = x1, y = y)
data_old
bandwidth <- 1
data <- data.frame(x1 = x1, y1 = y)
data$y1 <- y/x1
## Classification forest with default settings
rf1 <- ranger(y1~x1, data = data,
num.trees = 1000,
min.node.size = 30,
replace = FALSE, sample.fraction = 1,
splitrule = "extratrees"
)
pred_1 <- predict(rf1,
data = data.frame(x1 =seq(0, 1, length.out =n_test),
y1 = rep(0, n_test) ))
plot(Vectorize(f1), 0, 1,)
lines(seq(0, 1, length.out =n_test), pred_1$predictions, col = 'green')
